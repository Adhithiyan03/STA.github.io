---
title: "Human-Robot Collaborative Control for Robotic Manipulation" 
excerpt: |
  Comparing AR VR and Speech Interfaces for Robot Pick and Place tasks <br/>
  <videowidth="500" height="300" controls>
    <source src="/STA.github.io/images/Video_3_0.mp4" type="video/mp4">
    Your browser does not support the video tag.
  </video>
collection: portfolio
---
Research Questions
Is VR/Verbal interface better than traditional KBM interface?
Can we actually use this study to make interfaces that fit how users naturally express themselves?
Scope
Collaborative Human-Robot Control
Robotic Manipulation / Pick-Placing
Concept
Comparing 3 Approaches
Computer-based (KBM), Virtual Reality (VR), Voice Activation (VO)
User Study
Categorizing interface elements based on perceived behaviors


Robot control interfaces are of paramount importance for human-robot collaboration, as they facilitate the expression of human intent to the robot. The interaction is influenced by the characteristics of each input device and method. This project examines various input interfaces that accelerate human-robot communication for specific applications and evaluates the results of a user study completed with these interfaces. The aim is to
better comprehend the systemic consequences of these interfaces and to provide a trustworthy foundation for designing more user friendly systems.

<div style="width: 30%; text-align: center;">
  <img src="/STA.github.io/images/Video_33_1.png" style="width: 100%; height: auto; display: block; margin: auto;">
</div>

<div style="text-align: center;">
  <video controls width="500">
    <source src="/STA.github.io/images/video_3_1.mp4" type="video/mp4">
  </video>
</div>
